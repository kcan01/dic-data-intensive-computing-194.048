runners:
  hadoop:
    jobconf:
      # Resource allocation
      mapreduce.map.memory.mb: 4096
      mapreduce.reduce.memory.mb: 8192
      mapreduce.map.java.opts: -Xmx3072m
      mapreduce.reduce.java.opts: -Xmx6144m
      
      # Parallelism settings
      mapreduce.job.reduces: 8
      
      # Performance optimization
      mapreduce.task.io.sort.mb: 800
      mapreduce.task.io.sort.factor: 64
      mapreduce.map.sort.spill.percent: 0.90
      
      # I/O optimization
      mapreduce.map.output.compress: true
      mapreduce.map.output.compress.codec: org.apache.hadoop.io.compress.SnappyCodec
      mapreduce.output.fileoutputformat.compress: true
      mapreduce.output.fileoutputformat.compress.codec: org.apache.hadoop.io.compress.SnappyCodec
      
      # Speculative execution
      mapreduce.map.speculative: true
      mapreduce.reduce.speculative: true
      
      # Split size configuration
      mapreduce.input.fileinputformat.split.maxsize: 134217728
    
    # mrjob specific settings
    max_reduces: 8  # Controls number of reduce tasks
    hadoop_map_memory: 4096M
    hadoop_reduce_memory: 8192M
    compression_codec: snappy